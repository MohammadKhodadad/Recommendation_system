{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\r\n",
        "!pip install torch-geometric"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tqdm\r\n",
        "import torch\r\n",
        "from torch.nn import Linear\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.optim import Adam\r\n",
        "import torch_geometric\r\n",
        "from torch_geometric.data import Data,HeteroData\r\n",
        "from torch_geometric.data import DataLoader\r\n",
        "from torch_geometric.datasets import MovieLens\r\n",
        "from torch_geometric.nn import RGCNConv\r\n",
        "from torch_geometric.utils import dropout_adj\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "outputs": [],
      "execution_count": 368,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625706904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=MovieLens(root='.') \r\n",
        "ratings=pd.read_csv('raw/ml-latest-small/ratings.csv')\r\n",
        "ratings.drop_duplicates(inplace=True)\r\n",
        "titles=pd.read_csv('raw/ml-latest-small/movies.csv')\r\n",
        "titles.drop_duplicates(inplace=True,subset=['title'])"
      ],
      "outputs": [],
      "execution_count": 369,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625707907
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=ratings.copy()[['userId','movieId','rating']]\r\n",
        "movieId_dict={i:j for j,i in enumerate(df['movieId'].unique())}\r\n",
        "userId_dict={i:j for j,i in enumerate(df['userId'].unique())}"
      ],
      "outputs": [],
      "execution_count": 370,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625708077
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ML(Dataset):\r\n",
        "    def __init__(self, df):\r\n",
        "        self.users=np.unique(df['userId'])\r\n",
        "        self.movies=np.unique(df['movieId'])\r\n",
        "        self.edges=df\r\n",
        "        self.edges.rating=(self.edges.rating/5).astype('float32')\r\n",
        "        self.movieId_dict={i:j for j,i in enumerate(df['movieId'].unique())}\r\n",
        "        self.userId_dict={i:j for j,i in enumerate(df['userId'].unique())}\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.edges)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        row=self.edges.iloc[idx]\r\n",
        "        userId=torch.tensor(self.userId_dict[row['userId']])\r\n",
        "        movieId=torch.tensor(self.movieId_dict[row['movieId']])\r\n",
        "        rating=torch.tensor(row['rating'])\r\n",
        "        rating=rating.type(torch.cuda.FloatTensor)\r\n",
        "        # rating.type('torch.FloatTensor')\r\n",
        "        return {'userId':userId,\r\n",
        "         'movieId': movieId,\r\n",
        "         'rating': rating}\r\n"
      ],
      "outputs": [],
      "execution_count": 371,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625708442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=ML(df)"
      ],
      "outputs": [],
      "execution_count": 372,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625708602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Recommender1(torch.nn.Module):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        num_users,\r\n",
        "        num_items,\r\n",
        "        embedding_size=128\r\n",
        "    ):\r\n",
        "        super(Recommender1, self).__init__()\r\n",
        "        self.user_embedding = torch.nn.Embedding(\r\n",
        "            num_embeddings=num_users,\r\n",
        "            embedding_dim=embedding_size\r\n",
        "        )\r\n",
        "        \r\n",
        "        self.item_embedding = torch.nn.Embedding(\r\n",
        "            num_embeddings=num_items,\r\n",
        "            embedding_dim=embedding_size\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(\r\n",
        "        self,\r\n",
        "        users,movies\r\n",
        "    ):\r\n",
        "        user_embedding = F.dropout(F.relu(self.user_embedding(users)))\r\n",
        "        item_embedding = F.dropout(F.relu(self.item_embedding(movies)\r\n",
        "        ))\r\n",
        "        return user_embedding, item_embedding\r\n",
        "\r\n",
        "     "
      ],
      "outputs": [],
      "execution_count": 373,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625709238
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader=DataLoader(dataset,batch_size=32,shuffle=True)"
      ],
      "outputs": [],
      "execution_count": 374,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625709507
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = Recommender1(num_users=len(userId_dict),num_items=len(movieId_dict),embedding_size=128).to(device)"
      ],
      "outputs": [],
      "execution_count": 375,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625712716
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(user_embedding,movie_embedding,ratings):\r\n",
        "    out=torch.sigmoid((user_embedding*movie_embedding).sum(dim=-1))\r\n",
        "    loss = F.binary_cross_entropy(out, ratings)\r\n",
        "    mae = F.l1_loss(out, ratings)\r\n",
        "    return loss,mae"
      ],
      "outputs": [],
      "execution_count": 376,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625712877
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs=100):\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "    best_loss = float('inf')\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        model.train()\r\n",
        "        train_loss = 0.0\r\n",
        "        train_mae = 0.0\r\n",
        "        for batch in tqdm.tqdm(data_loader):\r\n",
        "            userId=batch['userId'].to(device)\r\n",
        "            movieId=batch['movieId'].to(device)\r\n",
        "            rating=batch['rating'].to(device)\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            user_embedding, item_embedding = model(userId, movieId)\r\n",
        "            loss , mae= loss_fn(user_embedding, item_embedding,rating)\r\n",
        "            train_loss += loss.item()\r\n",
        "            train_mae += mae.item()\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "        avg_train_loss = train_loss / len(data_loader)\r\n",
        "        avg_mae = train_mae / len(data_loader)\r\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, mae: {avg_mae:.4f}\")\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 377,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685625713038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 3152/3152 [00:35<00:00, 89.48it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 89.87it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 88.93it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 89.97it/s]\n100%|██████████| 3152/3152 [00:34<00:00, 91.71it/s]\n100%|██████████| 3152/3152 [00:34<00:00, 90.80it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 89.96it/s]\n100%|██████████| 3152/3152 [00:34<00:00, 90.65it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 89.72it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 90.05it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 89.96it/s]\n100%|██████████| 3152/3152 [00:34<00:00, 91.18it/s]\n100%|██████████| 3152/3152 [00:35<00:00, 89.90it/s]\n100%|██████████| 3152/3152 [00:34<00:00, 90.66it/s]\n 36%|███▋      | 1149/3152 [00:12<00:21, 92.18it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/20, Train Loss: 15.8275, mae: 0.2953\nEpoch 2/20, Train Loss: 10.2382, mae: 0.2823\nEpoch 3/20, Train Loss: 6.5506, mae: 0.2624\nEpoch 4/20, Train Loss: 4.4130, mae: 0.2449\nEpoch 5/20, Train Loss: 3.1784, mae: 0.2316\nEpoch 6/20, Train Loss: 2.4334, mae: 0.2229\nEpoch 7/20, Train Loss: 1.9316, mae: 0.2149\nEpoch 8/20, Train Loss: 1.6448, mae: 0.2093\nEpoch 9/20, Train Loss: 1.4246, mae: 0.2058\nEpoch 10/20, Train Loss: 1.2768, mae: 0.2033\nEpoch 11/20, Train Loss: 1.1631, mae: 0.2008\nEpoch 12/20, Train Loss: 1.0721, mae: 0.1988\nEpoch 13/20, Train Loss: 0.9885, mae: 0.1973\nEpoch 14/20, Train Loss: 0.9328, mae: 0.1960\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [378]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [377]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      8\u001b[0m train_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(data_loader):\n\u001b[1;32m     10\u001b[0m     userId\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     movieId\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Input \u001b[0;32mIn [371]\u001b[0m, in \u001b[0;36mML.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m row\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medges\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     14\u001b[0m userId\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muserId_dict[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m---> 15\u001b[0m movieId\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmovieId_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m rating\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m rating\u001b[38;5;241m=\u001b[39mrating\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 378,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685626220020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=(model.item_embedding(torch.tensor(range(len(movieId_dict))).to('cuda'))).detach().cpu().numpy()"
      ],
      "outputs": [],
      "execution_count": 379,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685626221954
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titles_2=titles.copy()\r\n",
        "titles_2.index=titles_2.movieId\r\n",
        "df['name_']=df.movieId.apply(lambda x:titles_2.loc[x]['title'] if x in titles_2.index else 'no_name')\r\n"
      ],
      "outputs": [],
      "execution_count": 380,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685626237376
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_=pd.DataFrame({'movieId':list(dataset.movieId_dict.keys())})\r\n",
        "\r\n",
        "movies_['name_']=movies_.movieId.apply(lambda x:titles_2.loc[x]['title'] if x in titles_2.index else 'no_name')"
      ],
      "outputs": [],
      "execution_count": 381,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685626237700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similarity(name):\r\n",
        "  row_movie=df[df.name_.apply(lambda x: name in x.lower() )].iloc[0]\r\n",
        "  movieId=dataset.movieId_dict[row_movie['movieId']]\r\n",
        "  row=embeddings[movieId]\r\n",
        "  similarity=np.matmul(row,embeddings.T)/np.sqrt((row**2).sum())/np.sqrt((embeddings**2).sum(axis=1))\r\n",
        "  new_df=movies_.copy()\r\n",
        "  new_df['sim']=similarity\r\n",
        "  new_df=new_df.sort_values(by='sim',ascending=False)\r\n",
        "  return new_df.iloc[:20]"
      ],
      "outputs": [],
      "execution_count": 382,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685626237848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_similarity('harry potter')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 384,
          "data": {
            "text/plain": "      movieId                                              name_       sim\n457      4896  Harry Potter and the Sorcerer's Stone (a.k.a. ...  1.000000\n1258    47491                 Adam's Apples (Adams æbler) (2005)  0.344224\n1052    50872                                 Ratatouille (2007)  0.317355\n12        223                                      Clerks (1994)  0.304903\n734      2717                             Ghostbusters II (1989)  0.299852\n465       253  Interview with the Vampire: The Vampire Chroni...  0.298314\n1812     4299                            Knight's Tale, A (2001)  0.297458\n531       165                  Die Hard: With a Vengeance (1995)  0.297325\n6289    60522     Machine Girl, The (Kataude mashin gâru) (2008)  0.295369\n6699     3330                       Splendor in the Grass (1961)  0.295124\n8448     8921                            Rose Tattoo, The (1955)  0.294618\n5371     5083                                  Rare Birds (2001)  0.290155\n5035   152270                                    The Wait (2015)  0.283943\n6042    33085                      Amityville Horror, The (2005)  0.283294\n1774     1035                         Sound of Music, The (1965)  0.283243\n8741     3626  8 ½ Women (a.k.a. 8 1/2 Women) (a.k.a. Eight a...  0.282333\n6371     1995              Poltergeist II: The Other Side (1986)  0.280707\n3537   128520                          The Wedding Ringer (2015)  0.279619\n481         2                                     Jumanji (1995)  0.279527\n2771     5810                                      8 Mile (2002)  0.277541",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>name_</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>457</th>\n      <td>4896</td>\n      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1258</th>\n      <td>47491</td>\n      <td>Adam's Apples (Adams æbler) (2005)</td>\n      <td>0.344224</td>\n    </tr>\n    <tr>\n      <th>1052</th>\n      <td>50872</td>\n      <td>Ratatouille (2007)</td>\n      <td>0.317355</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>223</td>\n      <td>Clerks (1994)</td>\n      <td>0.304903</td>\n    </tr>\n    <tr>\n      <th>734</th>\n      <td>2717</td>\n      <td>Ghostbusters II (1989)</td>\n      <td>0.299852</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>253</td>\n      <td>Interview with the Vampire: The Vampire Chroni...</td>\n      <td>0.298314</td>\n    </tr>\n    <tr>\n      <th>1812</th>\n      <td>4299</td>\n      <td>Knight's Tale, A (2001)</td>\n      <td>0.297458</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>165</td>\n      <td>Die Hard: With a Vengeance (1995)</td>\n      <td>0.297325</td>\n    </tr>\n    <tr>\n      <th>6289</th>\n      <td>60522</td>\n      <td>Machine Girl, The (Kataude mashin gâru) (2008)</td>\n      <td>0.295369</td>\n    </tr>\n    <tr>\n      <th>6699</th>\n      <td>3330</td>\n      <td>Splendor in the Grass (1961)</td>\n      <td>0.295124</td>\n    </tr>\n    <tr>\n      <th>8448</th>\n      <td>8921</td>\n      <td>Rose Tattoo, The (1955)</td>\n      <td>0.294618</td>\n    </tr>\n    <tr>\n      <th>5371</th>\n      <td>5083</td>\n      <td>Rare Birds (2001)</td>\n      <td>0.290155</td>\n    </tr>\n    <tr>\n      <th>5035</th>\n      <td>152270</td>\n      <td>The Wait (2015)</td>\n      <td>0.283943</td>\n    </tr>\n    <tr>\n      <th>6042</th>\n      <td>33085</td>\n      <td>Amityville Horror, The (2005)</td>\n      <td>0.283294</td>\n    </tr>\n    <tr>\n      <th>1774</th>\n      <td>1035</td>\n      <td>Sound of Music, The (1965)</td>\n      <td>0.283243</td>\n    </tr>\n    <tr>\n      <th>8741</th>\n      <td>3626</td>\n      <td>8 ½ Women (a.k.a. 8 1/2 Women) (a.k.a. Eight a...</td>\n      <td>0.282333</td>\n    </tr>\n    <tr>\n      <th>6371</th>\n      <td>1995</td>\n      <td>Poltergeist II: The Other Side (1986)</td>\n      <td>0.280707</td>\n    </tr>\n    <tr>\n      <th>3537</th>\n      <td>128520</td>\n      <td>The Wedding Ringer (2015)</td>\n      <td>0.279619</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>0.279527</td>\n    </tr>\n    <tr>\n      <th>2771</th>\n      <td>5810</td>\n      <td>8 Mile (2002)</td>\n      <td>0.277541</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 384,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1685626254071
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}